{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증(Cross Validation)\n",
    "\n",
    "#### 테스트 데이터에만 과적합 될 수 있으므로 데이터를 여러개로 나누어 테스트를 여러번 수행하여 평균 정확도를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9333\n",
      "교차 검증 정확도: [0.98 0.92 0.98]\n",
      "교차 검증 평균 정확도: 0.96\n"
     ]
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "\n",
    "# train(학습) 데이터와 test(검증) 데이터 세트로 분리 : 80%:20%, 120개(train),30개(test)\n",
    "X_train,X_test,y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=11)  # random seed를 고정\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "\n",
    "# 학습\n",
    "dt_clf.fit(X_train,y_train)\n",
    "\n",
    "# 예측\n",
    "pred = dt_clf.predict(X_test)  # y값 예측\n",
    "\n",
    "#정확도 측정 : 1회만 예측한 결과의 정확도\n",
    "print('정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 교차 검증(cross validation)\n",
    "# cross_val_score에 들어가는 매개변수는 (모델 명, 훈련데이터, 타깃, cv) \n",
    "cv_score = cross_val_score(dt_clf,iris_data.data,iris_data.target,\n",
    "                           scoring='accuracy',cv=3) # 3개로 쪼개어 검증\n",
    "# 데이터셋을 3개로 쪼개어 검증(fit,predict를 3회 수행)\n",
    "# 내부적으로 Stratified K-Fold가 사용됨, 평가지표를 하나만 구할 수 있어서 \n",
    "# StratifiedKFold 사용 권장\n",
    "\n",
    "print('교차 검증 정확도:',cv_score)\n",
    "print('교차 검증 평균 정확도:',cv_score.mean())\n",
    "# -------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold 교차 검증\n",
    "#### : K번 만큼 폴드(Fold)된 각각의 데이터 세트로 학습과 검증을 K번 만큼 반복하여 평균 정확도를 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "iris = load_iris()\n",
    "features = iris.data  # X, 피쳐\n",
    "label = iris.target   # Y, 레이블\n",
    "\n",
    "features.shape  # (150,4)\n",
    "label.shape     # (150,)\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)  # Estimator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 번 폴드 교차검증 정확도: 1.0 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "검증 데이터의 인덱스:\n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "# 2 번 폴드 교차검증 정확도: 0.9667 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "검증 데이터의 인덱스:\n",
      " [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "# 3 번 폴드 교차검증 정확도: 0.8667 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "검증 데이터의 인덱스:\n",
      " [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "# 4 번 폴드 교차검증 정확도: 0.9333 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "검증 데이터의 인덱스:\n",
      " [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "# 5 번 폴드 교차검증 정확도: 0.8333 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "검증 데이터의 인덱스:\n",
      " [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "K폴드 교차 검증 평균 정확도: 0.92\n"
     ]
    }
   ],
   "source": [
    "# 5개 폴드 세트로 분리\n",
    "kfold = KFold(n_splits = 5)   # class의 instance생성\n",
    "cv_accuracy = []  # 교차 검증 정확도 리스트\n",
    "n_iter = 0  # 반복횟수\n",
    "\n",
    "for train_index,test_index in kfold.split(features):\n",
    "    # kfold.split()함수 : X데이터 features를 분리하여 학습/검증용 데이터의 인덱스를 반환\n",
    "\n",
    "\n",
    "    # 150개 데이터\n",
    "    # k값(n_splits) : 폴드 세트 갯수,   학습:검증    검증 데이터의 비율\n",
    "    #       2       :        2           75:75         1/2 (50%)\n",
    "    #       3       :        3          100:50         1/3 (33%)\n",
    "    #       4       :        4          112:38         1/4 (25%)\n",
    "    #       5       :        5          120:30         1/5 (20%)   <- 여기서 쓰는 것\n",
    "    #       6       :        6          125:25         1/6 (16.7%)\n",
    "#    print(train_index) # test-train-train-train-train / train-test-train-train-train ...\n",
    "#    print(test_index)  # index값들임\n",
    "    \n",
    "    X_train = features[train_index]\n",
    "    X_test = features[test_index]\n",
    "    \n",
    "    y_train = label[train_index]\n",
    "    y_test = label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter +=1\n",
    "    \n",
    "    # 반복시마다 정확도 측정\n",
    "    accuracy = round(accuracy_score(y_test,pred),4)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    print('#',n_iter,'번 폴드 교차검증 정확도:',accuracy,\n",
    "          '학습 데이터의 크기:',X_train.shape[0],\n",
    "          '검증 데이터의 크기:',X_test.shape[0])\n",
    "    \n",
    "    print('학습 데이터의 인덱스:\\n',train_index)\n",
    "    print('검증 데이터의 인덱스:\\n',test_index)\n",
    "    \n",
    "print('K폴드 교차 검증 평균 정확도:',round(np.mean(cv_accuracy),4))  # 0.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold : 필수 사용!!\n",
    "#### label이 지나치게 불균형 분포를 이룰 때 레이블의 분포를 균일하게 폴드시키는 방식\n",
    "#### 분포 모델에서만 가능(회귀모델 지원되지 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 1 번 폴드 세트]\n",
      "2    42\n",
      "0    42\n",
      "1    36\n",
      "Name: label, dtype: int64\n",
      "\n",
      "[ 2 번 폴드 세트]\n",
      "1    46\n",
      "2    40\n",
      "0    34\n",
      "Name: label, dtype: int64\n",
      "\n",
      "[ 3 번 폴드 세트]\n",
      "0    46\n",
      "2    37\n",
      "1    37\n",
      "Name: label, dtype: int64\n",
      "\n",
      "[ 4 번 폴드 세트]\n",
      "2    41\n",
      "1    40\n",
      "0    39\n",
      "Name: label, dtype: int64\n",
      "\n",
      "[ 5 번 폴드 세트]\n",
      "1    41\n",
      "2    40\n",
      "0    39\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data,columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()\n",
    "\n",
    "kfold = KFold(n_splits=5,shuffle=True)  # shuffle과 Stratified 와는 성능이 다름\n",
    "n_iter = 0\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('\\n[',n_iter,'번 폴드 세트]')\n",
    "    print(label_train.value_counts())  # 120개\n",
    "    print(label_test.value_counts())   # 30개, 레이블이 불균형 분포를 이룬다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 1 번 폴드 세트]\n",
      "2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "\n",
      "[ 2 번 폴드 세트]\n",
      "2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "\n",
      "[ 3 번 폴드 세트]\n",
      "2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "\n",
      "[ 4 번 폴드 세트]\n",
      "2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "\n",
      "[ 5 번 폴드 세트]\n",
      "2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# StratifiedKFold : 레이블의 분포가 균일하게 분리된다, 정확도 향상\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index,test_index in skf.split(iris_df,iris_df['label']):\n",
    "    n_iter+=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('\\n[',n_iter,'번 폴드 세트]')\n",
    "    print(label_train.value_counts())  # 120개\n",
    "    print(label_test.value_counts())   # 30개\n",
    "    # 원본과 같은 비율로 레이블이 균형 분포를 이룬다\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 번 폴드 교차검증 정확도: 0.9667 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [ 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  60  61  62  63  64  65  66  67  68  69  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "검증 데이터의 인덱스:\n",
      " [  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57\n",
      "  58  59 100 101 102 103 104 105 106 107 108 109]\n",
      "# 2 번 폴드 교차검증 정확도: 0.9667 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [  0   1   2   3   4   5   6   7   8   9  20  21  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  70  71  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "검증 데이터의 인덱스:\n",
      " [ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67\n",
      "  68  69 110 111 112 113 114 115 116 117 118 119]\n",
      "# 3 번 폴드 교차검증 정확도: 0.9 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "검증 데이터의 인덱스:\n",
      " [ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77\n",
      "  78  79 120 121 122 123 124 125 126 127 128 129]\n",
      "# 4 번 폴드 교차검증 정확도: 0.9667 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 140 141 142 143 144 145 146 147 148 149]\n",
      "검증 데이터의 인덱스:\n",
      " [ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87\n",
      "  88  89 130 131 132 133 134 135 136 137 138 139]\n",
      "# 5 번 폴드 교차검증 정확도: 1.0 학습 데이터의 크기: 120 검증 데이터의 크기: 30\n",
      "학습 데이터의 인덱스:\n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127\n",
      " 128 129 130 131 132 133 134 135 136 137 138 139]\n",
      "검증 데이터의 인덱스:\n",
      " [ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97\n",
      "  98  99 140 141 142 143 144 145 146 147 148 149]\n",
      "StratifiedKFold 교차 검증 평균 정확도: 0.952\n"
     ]
    }
   ],
   "source": [
    "#  StratifiedKFold를 사용하여 학습 및 예측과 정확도 측정(회귀 모델에서는 사용불가능)\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "cv_accuaracy = []\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df,iris_df['label']): # Y레이블을 반드시 인자로 사용\n",
    "    X_train = features[train_index]\n",
    "    X_test = features[test_index]\n",
    "    \n",
    "    y_train = label[train_index]\n",
    "    y_test = label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter +=1\n",
    "    \n",
    "    # 반복 시 마다 정확도 측정\n",
    "    accuracy = round(accuracy_score(y_test,pred),4)\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "    print('#',n_iter,'번 폴드 교차검증 정확도:',accuracy,\n",
    "          '학습 데이터의 크기:',X_train.shape[0],\n",
    "          '검증 데이터의 크기:',X_test.shape[0])\n",
    "    \n",
    "    print('학습 데이터의 인덱스:\\n',train_index)\n",
    "    print('검증 데이터의 인덱스:\\n',test_index)\n",
    "\n",
    "# StratifiedKFold로 반복된 정확도를 합하여 평균 정확도 계산\n",
    "print('StratifiedKFold 교차 검증 평균 정확도:',round(np.mean(cv_accuracy),4))  # 0.96\n",
    "\n",
    "# StratifiedKFold로 레이블의 분포를 원본과 같이 균일하게 폴드를 생성하여 학습시키므로\n",
    "# 정확도가 향상됨 : 0.92 --> 0.96\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "#### 교차 검증과 파라메터 집합을 만들어 주면 최적의 파라메터 값을 구해줌 (파라메터=매개변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data,iris.target, \n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=11)\n",
    "dt_clf = DecisionTreeClassifier(random_state =11) # Estimator\n",
    "\n",
    "# 파라메터들을 dict 형태로 설정\n",
    "parameters = {'max_depth':[1,2,3],'min_samples_split':[2,3] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.677083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.677083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.675000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.675000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.950000                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.950000                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.958333                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.958333                1   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \n",
       "0            0.666667            0.677083            0.677083  \n",
       "1            0.666667            0.677083            0.677083  \n",
       "2            0.979167            0.979167            0.958333  \n",
       "3            0.979167            0.979167            0.958333  \n",
       "4            0.989583            0.989583            0.968750  \n",
       "5            0.989583            0.989583            0.968750  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree = GridSearchCV(dt_clf,param_grid=parameters,refit=True,\n",
    "                         return_train_score=True)\n",
    "grid_tree.fit(X_train,y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_tree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score',\n",
    "          'split0_train_score','split1_train_score','split2_train_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라메터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.9583333333333333\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라메터:',grid_tree.best_params_)\n",
    "print('GridSearchCV 최고 정확도:',grid_tree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "pred = grid_tree.predict(X_test)\n",
    "print('정확도:',accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=11, splitter='best')\n",
      "정확도: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "estimator = grid_tree.best_estimator_  # DecisionTreeClassifier의 인스턴스\n",
    "print(estimator)\n",
    "pred = estimator.predict(X_test)\n",
    "print('정확도:',accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
